---
title: "De datos crudos a modelo desplegado: construyendo un pipeline de ML con AutoML y Vertex AI"
date: 2025-11-29
---

# De datos crudos a modelo desplegado: construyendo un pipeline de ML con AutoML y Vertex AI

En esta pr√°ctica trabaj√© con **Vertex AI Pipelines**, la herramienta de Google Cloud dise√±ada para automatizar flujos de Machine Learning. El desaf√≠o consisti√≥ en construir un pipeline completo que va desde datos crudos hasta la creaci√≥n, evaluaci√≥n y potencial despliegue de un modelo entrenado con AutoML.  
A lo largo del proceso aprend√≠ a combinar componentes personalizados, servicios nativos de Vertex AI y BigQuery para crear una soluci√≥n reproducible, escalable y alineada al ciclo **CRISP-DM**.

---

## Contexto

En proyectos reales, un modelo no se entrena solo una vez. Se necesitan procesos **autom√°ticos**, **repetibles** y **modulares**, especialmente cuando se trabaja con datos que evolucionan. Vertex AI Pipelines resuelve este problema permitiendo definir flujos de ML como c√≥digo, controlando datos, artefactos y dependencias entre pasos.

El objetivo de este laboratorio fue simular un pipeline profesional que:

1. Recibe datos tabulares,
2. Crea un dataset en Vertex AI,
3. Entrena un modelo AutoML de clasificaci√≥n,
4. Eval√∫a m√©tricas y toma decisiones autom√°ticas,
5. Y opcionalmente despliega el modelo en un endpoint si cumple un umbral de calidad.

Este ejercicio forma parte de mi formaci√≥n en Inteligencia Artificial, integrando habilidades de MLOps, AutoML y orquestaci√≥n de pipelines en la nube.

---

## Objetivos

- Construir componentes personalizados con el SDK de Kubeflow Pipelines.
- Conectar componentes usando artefactos y dependencias declaradas.
- Configurar e iniciar un pipeline simple de introducci√≥n.
- Crear un pipeline completo de AutoML Tabular (dataset ‚Üí entrenamiento ‚Üí evaluaci√≥n ‚Üí despliegue).
- Analizar artefactos generados en Vertex AI (datasets, modelos, m√©tricas).
- Comprender c√≥mo automatizar decisiones basadas en umbrales de desempe√±o.

---

## Actividades (con tiempos estimados)

| Actividad | Tiempo | Resultado Esperado |
|----------|:------:|--------------------|
| Configuraci√≥n del entorno | 10 min | Notebook funcionando con dependencias instaladas |
| Pipeline introductorio (hello-world) | 15 min | Pipeline funcional con tres componentes |
| Construcci√≥n del dataset en Vertex AI | 10 min | Artefacto `system.Dataset` creado desde BigQuery |
| Entrenamiento con AutoML | 20 min | Job iniciado correctamente (entrenamiento demora ~1h) |
| Evaluaci√≥n y l√≥gica condicional | 10 min | Componente personalizado ejecut√°ndose |
| Revisi√≥n de artefactos y reflexi√≥n | 10 min | Entendimiento del flujo completo |

---

## Desarrollo

### 1. Preparaci√≥n del entorno

Comenc√© en Vertex AI Workbench y configur√© todas las librer√≠as necesarias (KFP, google-cloud-aiplatform, pipeline components).  
Luego defin√≠ variables del proyecto, bucket de almacenamiento y regi√≥n, asegurando que todos los componentes del pipeline pudieran escribir artefactos en Cloud Storage.

---

### 2. Pipeline introductorio: ‚Äúhello-world‚Äù

Antes de pasar a AutoML constru√≠ un pipeline sencillo formado por tres componentes:

- `product_name`: recibe un string.
- `emoji`: convierte un texto en un emoji.
- `build_sentence`: combina los resultados y arma una frase final.

El pipeline ejecut√≥ correctamente y gener√≥:

**Salida final:** `Vertex AI Pipelines is ‚ú®`

Esta primera parte me permiti√≥ entender:
- c√≥mo escribir componentes como funciones Python,
- c√≥mo declarar entradas y salidas,
- c√≥mo compilar y ejecutar un pipeline en Vertex AI.

---

### 3. Pipeline de AutoML: datos crudos ‚Üí modelo

El pipeline principal incluy√≥ cinco pasos:

1. **TabularDatasetCreateOp**  
   Crea un dataset desde BigQuery.

2. **AutoMLTabularTrainingJobRunOp**  
   Entrena un modelo AutoML de clasificaci√≥n multiclase sobre el dataset ‚ÄúDry Beans‚Äù.

3. **Componente personalizado de evaluaci√≥n**  
   Extrae m√©tricas, renderiza matriz de confusi√≥n y curva ROC, y decide si el modelo es lo suficientemente bueno.

4. **Condici√≥n (dsl.Condition)**  
   Si el m√©trico AUC supera 0.95 ‚Üí se despliega el modelo.

5. **ModelDeployOp**  
   Despliega el modelo en un endpoint (solo si pasa la condici√≥n).

---

### 4. Ejecuci√≥n del pipeline

La ejecuci√≥n se inici√≥ correctamente, y los primeros pasos se completaron antes de que se cerrara la sesi√≥n del laboratorio.  
El entrenamiento de AutoML empez√≥ a correr (este paso demora alrededor de 1 hora y es normal que contin√∫e ejecut√°ndose m√°s all√° de la sesi√≥n del lab).

Logr√© capturar evidencias del DAG completo, del dataset creado y del inicio del entrenamiento.

---

## Evidencias

### üëâ Evidencia 1: Pipeline introductorio funcionando  
    ![Evidencia build-sentence output](../assets/p16_intro_pipeline_output_06.png){ width="700" }

### üëâ Evidencia 2: DAG de la pipeline de AutoML  
    ![Pipeline AutoML DAG](../assets/p16_automl_beans_pipeline_07.png){ width="700" }

### üëâ Evidencia 3: Artefacto dataset creado correctamente  
    ![Dataset Artefact](../assets/p16_beans_dataset_artifact_08.png){ width="700" }

### üëâ Evidencia 4: Entrenamiento AutoML en ejecuci√≥n  
    ![AutoML Running](../assets/p16_beans_training_running_09.png){ width="700" }

Estas evidencias demuestran que el pipeline se inici√≥ de forma completa y que Vertex AI est√° gestionando todos los pasos correctamente.

---

## Reflexi√≥n

Esta pr√°ctica me permiti√≥ ver en acci√≥n c√≥mo se **industrializan** los modelos de Machine Learning en la nube.  
Lo m√°s relevante que aprend√≠:

- Una pipeline bien dise√±ada permite **repetibilidad** y **escalabilidad**, evitando procesos manuales.
- AutoML simplifica la experimentaci√≥n, pero sigue siendo fundamental entender c√≥mo orquestar datos, entrenamiento y despliegue.
- Los artefactos generados por Vertex AI permiten rastrear el linaje completo del sistema (datasets, modelos, m√©tricas, endpoints).
- Usar l√≥gica condicional dentro de un pipeline ayuda a automatizar decisiones sin intervenci√≥n humana.

### Qu√© mejorar√≠a
- Incorporar notificaciones autom√°ticas (Pub/Sub o Cloud Functions) para saber cu√°ndo termina el entrenamiento.
- A√±adir evaluaciones adicionales (por ejemplo, costo de confusi√≥n o m√©tricas por clase).

### Pr√≥ximos pasos
- Crear pipelines m√°s complejos usando TFX.
- Integrar validaci√≥n de datos con TensorFlow Data Validation.
- Probar pipelines con scheduling desde Cloud Scheduler.

---

## Referencias

- Google Cloud ‚Äì Vertex AI Documentation  
- Google Cloud ‚Äì Kubeflow Pipelines SDK  
- ‚ÄúDry Beans Dataset‚Äù, UCI Machine Learning Repository  
- Material del laboratorio de Google Cloud Skills Boost

